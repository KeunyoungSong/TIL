# 입력 차원(D), 샘플 수(N), 배치 크기(B) — Q&A 의식의 흐름 버전

> Type: Concept

## 상황/배경(Context)
“입력 차원 100”이라는 표현을 들었을 때 처음엔 “샘플이 100개”라는 뜻으로 받아들였다.  
이 오해를 풀기 위해 질문을 이어가며, 결국 `N(샘플 수)`, `D(입력 차원)`, `B(배치 크기)`가 서로 다른 축이라는 걸 이해하게 됐다.

---

## 질문 1) “입력 차원 100이면 샘플 100개야?”
아니다.

- **입력 차원(D)=100**: 샘플 1개가 100개의 값(특성)을 가진다.
- **샘플 수(N)=100**: 그런 샘플이 100개 있다.

즉, “100”이 무엇을 세는지부터 분리해야 한다.

## 질문 2) “그럼 동시에 존재하는 숫자들은 뭐가 있어?”
머신러닝에서 자주 같이 나오는 3개:

| 구분 | 의미 | 예 |
|---|---|---:|
| `N` | 샘플 수(데이터 개수) | 10,000 |
| `D` | 입력 차원(샘플 1개의 특성 수) | 100 |
| `B` | 배치 크기(한 번에 처리하는 샘플 수) | 32 |

## 질문 3) “그럼 데이터는 수치로 어떻게 표현해?”
탭 데이터/MLP 기준으로 데이터는 보통 행렬로 표현한다.

$$
X \in \mathbb{R}^{N \times D}
$$

예를 들어 `N=10,000`, `D=100`이면:

$$
X \in \mathbb{R}^{10000 \times 100}
$$

여기서
- 행(row) = 샘플
- 열(column) = 특성(feature)

즉 “행이 많아지면 샘플이 많아지는 것”이고, “열이 많아지면 입력 차원이 커지는 것”이다.

## 질문 4) “배치는 여기서 어디에 끼어들어?”
학습은 전체 `X`를 한 번에 넣지 않고, 일부 행을 뽑아 미니배치로 처리한다.

$$
X_{\text{batch}} \in \mathbb{R}^{B \times D}
$$

예를 들어 `B=32`, `D=100`이면:

$$
X_{\text{batch}} \in \mathbb{R}^{32 \times 100}
$$

## 질문 5) “그럼 한 샘플은 네트워크에 어떻게 들어가?”
한 샘플 `x_i`는 길이 `D`의 벡터다.

$$
x_i = [x_{i1}, x_{i2}, \ldots, x_{iD}]
$$

배치로 보면 `B`개의 샘플 벡터가 쌓여서 `B×D` 행렬(또는 텐서)로 한 번에 들어간다.

## 주의할 점(Caveats)
- CNN/Transformer에서는 입력이 벡터가 아니라 텐서라서, “입력 노드 D개” 표현이 덜 자연스럽다. 그때는 보통 shape로 말한다(예: `(B, C, H, W)`, `(B, T, d_model)`).
- `입력 차원(D)`과 `파라미터 수(#θ)`는 다른 개념이다.

## 한 줄 요약(Summary)
입력 차원 `D`는 “샘플 1개가 가진 특성 수”, 샘플 수 `N`은 “데이터 개수”, 배치 크기 `B`는 “한 번에 처리하는 샘플 수”이고, 보통 데이터는 `(N, D)`, 배치는 `(B, D)`로 표현한다.

